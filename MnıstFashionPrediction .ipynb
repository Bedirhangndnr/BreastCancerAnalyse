{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperas in c:\\users\\bedir\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (5.6.1)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (0.2.5)\n",
      "Requirement already satisfied: keras in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (2.4.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (0.3)\n",
      "Requirement already satisfied: jupyter in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (5.0.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (2.11.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.4.4)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (4.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (4.3.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (2.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (4.42.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.15.0)\n",
      "Requirement already satisfied: future in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (2.4)\n",
      "Requirement already satisfied: h5py in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from keras->hyperas) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from keras->hyperas) (5.3)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (4.6.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (7.5.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (5.1.4)\n",
      "Requirement already satisfied: notebook in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.0.3)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-core->nbconvert->hyperas) (227)\n",
      "Requirement already satisfied: decorator in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from traitlets>=4.2->nbconvert->hyperas) (4.4.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from h5py->keras->hyperas) (1.5.2)\n",
      "Requirement already satisfied: jupyter-client>=4.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->hyperas) (5.3.4)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (7.12.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (6.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (18.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.7.1)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->hyperas) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (1.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (19.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.14.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.4.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (2.2.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.5.2)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\bedir\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (4.42.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (1.3.0)\n",
      "Requirement already satisfied: future in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperas\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '_pywrap_tensorflow_internal' has no attribute 'TF_OK_swigconstant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a95cdad765f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OK_swigconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[0mTF_OK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '_pywrap_tensorflow_internal' has no attribute 'TF_OK_swigconstant'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '_pywrap_tensorflow_internal' has no attribute 'TF_OK_swigconstant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OK_swigconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[0mTF_OK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '_pywrap_tensorflow_internal' has no attribute 'TF_OK_swigconstant'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (C:\\Users\\bedir\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-c5b806e9e1d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnbconvert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPythonExporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVotingModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m from .utils import (\n\u001b[0;32m     13\u001b[0m     \u001b[0mremove_imports\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove_all_comments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_imports\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_string\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperas\\ensemble.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_from_yaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mVotingModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStrictVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtranspose_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mpy_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (C:\\Users\\bedir\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py)"
     ]
    }
   ],
   "source": [
    "from hyperas import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# install tensorflow 2.0 beta\n",
    "!pip install -q tensorflow-gpu==2.0.0-beta0\n",
    "\n",
    "# install GapCV\n",
    "!pip install -q gapcv\n",
    "\n",
    "# install hyperas\n",
    "!pip install -q hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.hyperas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-621d382dd5fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0muniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.hyperas'"
     ]
    }
   ],
   "source": [
    "from hyperas.distributions import uniform\n",
    "from tensorflow.hyperas import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (C:\\Users\\bedir\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d3595641c52a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStrictVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtranspose_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mpy_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (C:\\Users\\bedir\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fashion Mnıst dataset is consist fashion items as 70.000 grayscale image of 28*28 pixels each, with 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fashion MNIST dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist= keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist= keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data already splitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), ( X_test, y_test)= fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape,y_train_full.shape, X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is no validation set. Let's create one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28), (48000,), (12000, 28, 28), (12000,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since pixels intensities is between 0-255, we should scale these values by dividing 255 each value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train/255\n",
    "X_test= X_test/255\n",
    "X_valid= X_valid/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels information of this data:\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "    0 T-shirt/top\n",
    "    1 Trouser\n",
    "    2 Pullover\n",
    "    3 Dress\n",
    "    4 Coat\n",
    "    5 Sandal\n",
    "    6 Shirt\n",
    "    7 Sneaker\n",
    "    8 Bag\n",
    "    9 Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's give class name for each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandal\n",
      "T-shirt/top\n",
      "Trouser\n",
      "Shirt\n",
      "Trouser\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "for i in y_train[0:5]:\n",
    "    print(class_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_images(X_values,y_targets,n_rows=4,n_cols=10):\n",
    "    import matplotlib.pyplot as plt \n",
    "    plt.figure(figsize=(n_cols * 1.6, n_rows * 1))\n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            index = n_cols * row + col\n",
    "            plt.subplot(n_rows, n_cols, index + 1)\n",
    "            plt.imshow(X_values[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "            plt.axis('off')\n",
    "            plt.title(class_names[y_targets[index]], fontsize=12)\n",
    "    plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "    plt.show()\n",
    "display_images(X_train, y_train,3,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a simple neural network model for predict label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a basic model and observe accuracy. Than try to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This section for tensorboard. Not really importand for now. (Important but not now.)\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7690 - accuracy: 0.8068 - val_loss: 0.4190 - val_accuracy: 0.8817\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3708 - accuracy: 0.8971 - val_loss: 0.3310 - val_accuracy: 0.9080\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3164 - accuracy: 0.9107 - val_loss: 0.2970 - val_accuracy: 0.9159\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2860 - accuracy: 0.9188 - val_loss: 0.2728 - val_accuracy: 0.9222\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2632 - accuracy: 0.9254 - val_loss: 0.2543 - val_accuracy: 0.9277\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2449 - accuracy: 0.9307 - val_loss: 0.2400 - val_accuracy: 0.9326\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2300 - accuracy: 0.9353 - val_loss: 0.2282 - val_accuracy: 0.9352\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2169 - accuracy: 0.9382 - val_loss: 0.2177 - val_accuracy: 0.9398\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2053 - accuracy: 0.9426 - val_loss: 0.2092 - val_accuracy: 0.9419\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1953 - accuracy: 0.9444 - val_loss: 0.1988 - val_accuracy: 0.9442\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1862 - accuracy: 0.9474 - val_loss: 0.1944 - val_accuracy: 0.9452\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1784 - accuracy: 0.9491 - val_loss: 0.1864 - val_accuracy: 0.9483\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1711 - accuracy: 0.9516 - val_loss: 0.1797 - val_accuracy: 0.9488\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1646 - accuracy: 0.9533 - val_loss: 0.1750 - val_accuracy: 0.9507\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1587 - accuracy: 0.9548 - val_loss: 0.1698 - val_accuracy: 0.9518\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1533 - accuracy: 0.9565 - val_loss: 0.1661 - val_accuracy: 0.9523\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1483 - accuracy: 0.9578 - val_loss: 0.1627 - val_accuracy: 0.9537\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1436 - accuracy: 0.9590 - val_loss: 0.1587 - val_accuracy: 0.9552\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1392 - accuracy: 0.9603 - val_loss: 0.1546 - val_accuracy: 0.9572\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1350 - accuracy: 0.9619 - val_loss: 0.1525 - val_accuracy: 0.9571\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1314 - accuracy: 0.9627 - val_loss: 0.1500 - val_accuracy: 0.9576\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1276 - accuracy: 0.9640 - val_loss: 0.1471 - val_accuracy: 0.9588\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1242 - accuracy: 0.9653 - val_loss: 0.1452 - val_accuracy: 0.9590\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1210 - accuracy: 0.9659 - val_loss: 0.1431 - val_accuracy: 0.9587\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1179 - accuracy: 0.9670 - val_loss: 0.1407 - val_accuracy: 0.9607\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1152 - accuracy: 0.9679 - val_loss: 0.1382 - val_accuracy: 0.9603\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1123 - accuracy: 0.9688 - val_loss: 0.1367 - val_accuracy: 0.9619\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1098 - accuracy: 0.9694 - val_loss: 0.1353 - val_accuracy: 0.9609\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1074 - accuracy: 0.9701 - val_loss: 0.1334 - val_accuracy: 0.9617\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1048 - accuracy: 0.9710 - val_loss: 0.1312 - val_accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "# Build and compile a basic model\n",
    "def model_():\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")#  If we were doing binary classification or multilabel binary classification, then we would use the \"sigmoid\"\n",
    "                                                    #  (i.e., logistic) activation function in the output layer instead of the \"softmax\"\n",
    "                                                    #  activation function, and we would use the \"binary_crossentropy\" loss.      \n",
    "    ])\n",
    "       \n",
    "            \n",
    "    return model\n",
    "model=model_()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",  #  we use the \"sparse_categorical_crossentropy\" loss because we have sparse labels (i.e., for each instance, there is just a target class \n",
    "                                                       #  index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability\n",
    "                                                       #  per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]\n",
    "                                                       #  to represent class 3), then we would need to use the \"categorical_crossentropy\" loss instead. \n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take look to evaluation parameters improving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9232), started 1 day, 8:15:32 ago. (Use '!kill 9232' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b5fea59dd5c93dfe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b5fea59dd5c93dfe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yo can see how changed loss and accuracy values. Lets observe this change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a callback to earlystop. To do this, ve just can add **tf.keras.callbacks.EarlyStopping(patience=3)** Thiss code will stop training when validation loss not improve 3 time in a row. \n",
    "\n",
    "Normally, 3 is not good number for this. But in here, i try to understandable and traceable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, let's measure basic model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2752 - accuracy: 0.9003\n",
      "Train      [0.27524876594543457, 0.9002500176429749]\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8767\n",
      "Validation [0.34680190682411194, 0.8766666650772095]\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3684 - accuracy: 0.8703\n",
      "Test       [0.3683675229549408, 0.8702999949455261]\n"
     ]
    }
   ],
   "source": [
    "def print_accuracy():\n",
    "    print(\"Train     \", model.evaluate(X_train, y_train))\n",
    "    print(\"Validation\", model.evaluate(X_valid, y_valid))\n",
    "    print(\"Test      \", model.evaluate(X_test, y_test))\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=model_()\n",
    "#history = model.fit(X_train, y_train, epochs=30,\n",
    "#                    validation_data=(X_valid, y_valid),\n",
    "#                    callbacks=[tensorboard_cb,\n",
    "#                              tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\")]\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got 0.86 accuracy. Not good at all. Lets try to improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, i will try just learning rate set and find the best. Than shile using this learning rate, i change hidden layer, n_neurons etc.\n",
    "Lets find an learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-0c259d5223ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m history = model.fit(X_train, y_train, epochs=3,\n\u001b[0;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                    callbacks=[tensorboard_cb])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2694\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model=model_()\n",
    "history = model.fit(X_train, y_train, epochs=3,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.3607 - accuracy: 0.5365 - val_loss: 1.8457 - val_accuracy: 0.1997\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "        \n",
    "        \n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model=model_()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxV5b3v8c8v8zyRkJkwhSEgMoRJFIIFBFvFqQ5VW4fK9Ry9Vj2trbc9tvXV3vZY622trdYRbY+iRauiVsVKAAEZZQogIFNCgDAlEKYQ8tw/9paTYhICZGcnWd/367VfruHZa/+SR/Y3a3qWOecQERHvCgl2ASIiElwKAhERj1MQiIh4nIJARMTjFAQiIh6nIBAR8biwYBdwpkJjEl1YYmf6ZydiwS5G/sWhQ4eIjY0NdhnSAPVN29Ya/bN06dI9zrm0hta1uyBITs8i7rpHGVeYy73j88lMjA52SeJXXFxMUVFRsMuQBqhv2rbW6B8z29rYunYXBF07xVLQK41Xl5Ty6pJSrivMZVR+Kj3SYumXlRjs8kRE2p12FwQAf7hhEP/x2nLW76o+GQgAfTMTGF+QTlZiFH0zE+ibmUBEmE6DiIg0pV0GQWJ0OM9+ZygAS7fup2z/YdbsOMBHa3bx+D83nGwXERZCckw4PdLiGJCTxMDcRAbkJJGZGIWZzjCIiEA7DYL6huQlMyQvmckDs3lwUl8O19Syt7qGlWVVrCyrZO+hGj7feZDnPtnE8RO+cZVS4yIYmJvE0K4pjOqZSt/MBEJDFAwi4k3tPghOFRMRRkxKGLkpMXx9QObJ5UePn2DNjgOs3l7F8tJKlm+r5KO1FQBEh4fSOyOeoV2TGdG9E0O7pZAQFR6sH0FEpFV1uCBoTFR4KIO7JDO4SzLfHulbtrPqKAs372V5aSUl5Qd4ccFWnpm7mRCDflmJjOieomAQkQ7PM0HQkIzEKCYPzGbywGzAt9fw2bZKPt20l0837eXF+QoGEen4PB0Ep4oKD2Vkj06M7NEJaDoYBuYmUdS7M4O6JDEkL5mYCP0qRaR90rdXExoLhgVf7OHjzyt4bOZ6AMJDjaFdUxjdK42BuUkMzE0iKjw0mKWLiDSbguAM1A+G+yf05sDR43y2rZL5G/fw8boKfv2PdYDvstXCvGQm9s9gQkEGGYlRQa5cRKRxCoJzkBAVzpheaYzplcaDl/Zlb/Wxk4eSitfv5qG3SnjorRIG5CQyrm864/qm0zczXvcwiEiboiBoQZ3iIhlXkM64gnR+7BwbKqqZuWYXH63dxWMz1/PYzPVkJ0UzviCd8QXpDOuWQnio7nwWkeBSEASImdErPZ5e6fHcNbYnFQeP8vHaCmau2cUri7Yxdf4W4qPCKOrdmfEF6YzplUZitK5EEpHWpyBoJZ3jo7h+WBeuH9aFwzW1fLJhDx+t3cU/11YwY0U5YSHG8O4pjO+bztf6ppObEhPskkXEIxQEQRATEcaEfhlM6JfBiTrH8tL9zFxTwcw1O/nZjDX8bMYa+mTEM6EgnfEFGfTPTtB5BREJGAVBkIWGGEPyUhiSl8KPJvVh0+5q/uk/hPTErI08/vFGuqfFcs2QHK4alKMrkESkxSkI2pjuaXF0T4vjjtHd2Xeohg9LdvLGsu088v7n/OaDz7mwZypXDc5mYr9MoiN0r4KInDsFQRuWEhtx8rzClj2HeGNZGa8v2859r67goagSrhyUzQ3DutA3MyHYpYpIO6YgaCe6psZy/4Te3DuuFws37+PVxduYtriUlxZsZUBOItcNzeXy87OI1xhIInKGFATtTEiInby7+aeHavj7Z9t5bUkpP/77an7xzlquGJTFLRd0o3dGfLBLFZF2QkHQjiXHRnDbhd24dVRXVpRV8fLCrbyxbDuvLCplTK80pozuzgU9OumKIxFpkoKgAzCzk4PdPTipLy8v2sYL87Zw47MLKchM4I7R3fjGgCzdxSwiDdI3QweTHBvBXWN78skPx/LI1QOoOVHHfa+uYPQjs3hx/haOHj8R7BJFpI1REHRQUeGhXDs0lw/vHc0LtwwlNyWGn75dQtFvivnLp1s5VqtAEBEfBUEHFxJijO3TmVenjODl7w4nJzma/3xzNWN/U8zLC7dRU1sX7BJFJMgUBB5hZlzQM5W/3TmSv9w+jPTEKP7P31cx9tFiXl28jeMnFAgiXqUg8Bgz46L8NN74twuYeutQUuMi+OHrq/jab2fz2pJSahUIIp4TsCAws1wzm2Vma82sxMy+10AbM7PHzWyjma00s8GBqkf+lZlR1Lszb941iudvKSQhOowHpq/k0sfnMmtdBc65YJcoIq0kkHsEtcB/OOf6AiOAu8ys4JQ2k4B8/2sK8GQA65EGmBkX90lnxt0X8uSNg6mprePWqYu56bmFrN5eFezyRKQVBCwInHM7nHPL/NMHgbVA9inNJgMvOZ9PgSQzywxUTdI4M2PSeZl8eN8YfnpZAWvKD3DZE59w/2vLKa88EuzyRCSAWuUcgZl1BQYBC09ZlQ2U1psv46thIa0oIiyEW0d1o/gHY5kyujvvrNzB2EeL+c0H6zhcUxvs8kQkAAJ+Z7GZxQGvA/c65w6curqBt3zl4LSZTcF36Ij09HSKi4tbukxpwMhoyB8VyfT1Nfxx1hdMW7CJmwsiGNi54f9tqqur1TdtlPqmbQt2/1ggTwqaWTjwDvCBc+6xBtb/GSh2zr3in/8cKHLO7Whsm4WFhW7JkiWBKlkasXDTXn7y5mo2VFRzSb90fnpZP7KSov+lTXFxMUVFRcEpUJqkvmnbWqN/zGypc66woXWBvGrIgOeAtQ2FgN/bwLf9Vw+NAKqaCgEJnuHdO/HuPRfxwMTezF6/m3GPzeaZOZt0/4FIBxDIcwSjgJuBi81suf91qZndaWZ3+tu8B2wCNgLPAP8ewHrkHEWEhfDvRT2Zed8YRnTvxC/fW8tlf/iEpVv3B7s0ETkHATtH4Jz7hIbPAdRv44C7AlWDBEZuSgzPfaeQD0p28fMZJVz95HxuGNaFUXG690CkPdIw1HJWzIyJ/TO4KD+V3320nufnbeGdMEdNahlXDsrWMxBE2hENMSHnJDYyjB9/vYAZd19I5+gQ7n9tBTc+u5Btew8HuzQRaSYFgbSIgqwEfjwiil9e2Z9VZVVM/P0c/rJgCyfqdLhIpK1TEEiLCTHjxuF5fHDfaIbkJfOfb5Vw1Z/maagKkTZOQSAtLispmpduG8bvrhvI9sqjTP7jPP7ve2s5UqOH4Yi0RQoCCQgz44pB2fzz/jFcW5jD03M2ccnv5jD/iz3BLk1ETqEgkIBKjAnnV1cNYNqUEZjBt55ZyI//vorqYxq3SKStUBBIqxjRvRPvf280372wGy8v2saEx2bz8bpdwS5LRFAQSCuKjgjlJ98oYPqdFxAbGcZtU5dw18vLqDh4NNiliXiagkBa3ZC8ZN695yK+P6EXM9fsYtxvZ/Pa4lI9FU0kSBQEEhQRYSHcfXE+73/vIvpkJvDA6yu5+blFuhFNJAgUBBJU3dPimHbHCH5xRX+Wl1Zyye/m8OzcTboRTaQVKQgk6EJCjJtG5DHz/tFc0KMTv3h3LZc/8QmLNu8LdmkinqAgkDYjMzGaZ79TyB9uGETl4eNc++cFPDB9BfsP1QS7NJEOTUEgbYqZcdn5Wcy8fzT/a0x33li2nXGPzebtFeU6mSwSIAoCaZNiIsJ4cFJf3rnnQrKTo7nnlc+46bmFbNh1MNiliXQ4CgJp0/pkJPD3fx/Fw5P7sbKsiom/n8tP3lzF3upjwS5NpMNQEEibFxpifHtkV2b/YCw3De/CK4tKGftoMS8t2EKtnpkscs4UBNJupMRG8PPJ/Xn/exfRPzuRh94q4bIn5rFsm56ZLHIuFATS7uSnx/Pf3x3On24cTOXhGq55cj6/eGcNB44eD3ZpIu2SgkDaJTPj0vMy+fC+0Vw3NJfn5m3m4keLeW1JKXW6GU3kjCgIpF2Lj/INc/3WXaPokhLDA9NXcuWf5vGZDheJNJuCQDqEATlJTL/zAh679nx2VB3lyj/N5/5Xl1O2X2MXiZyOgkA6jJAQ46rBOXz8/SLuHNODd1bt4OJHZ/Or99ZSdUTnD0QaoyCQDicuMowfTerD7B8UcfnALJ6eu4mi38zi+U8267nJIg1QEEiHlZkYzaPfPJ8Zd19I38wEHn5nDRc9Moup8zZzrFaBIPIlBYF0eP2zE3n5jhG8OmUEPdJi+dmMNYx/bA7vr96p8YtEUBCIhwzv3olpU0bw0m3DiAwL4c6/LuXaPy9g8RYNdy3epiAQTzEzRvdK4x/fu4hfXtmfLXsP882nFvDt5xfpklPxLAWBeFJYaAg3Ds9jzg/G8uCkPqzeXsWVf5rP7VMXs27ngWCXJ9KqFATiadERofyvMT2Y+8BYfnBJbxZt2cek38/l/leXU7pP9yCINygIRIDYyDDuGtuTuQ+MZcpF3Xl31Q6+9tvZ/HxGiYa8lg5PQSBST1JMBA9e2pfiHxRx1eBsXpy/hYsemcWPXl/JmnIdMpKOSUEg0oDMxGh+ffUAPrxvDF8/L5O3lpdz6eNzufWFRSzRVUbSwSgIRJrQs3Mcv/nm+Xz64Nf4/oRerCir4pqnFnDdnxfw7sodujFNOoSwYBcg0h4kxoRz98X53HZhN15ZVMozczZx18vLSImN4JuFOdw4LI8unWKCXabIWVEQiJyBmIgwbr+wG7dc0JV5G/fw3wu38uzczTw9ZxOj89O4aUQeF/fpTGiIBbtUkWYLWBCY2fPAN4AK51z/BtYXAW8Bm/2L3nDOPRyoekRaUmiI78a00b3S2Fl1lFcWbWPa4m3c8dISshKjuGFYF24akUdybESwSxU5rUCeI5gKTDxNm7nOuYH+l0JA2qWMxCjuG9+LT354MU/dNIQeneP47cz1XPDrj3nordVs3nMo2CWKNClgewTOuTlm1jVQ2xdpa8JDQ5jYP4OJ/TNYv+sgf569iVcWbeMvn25ldH4aVw3OZnxBOjEROiIrbUuw/48caWYrgHLg+865kiDXI9IieqXH89trz+eHE3vz10+38vqy7Xxv2nJiIkKZ2D+DawtzGd4tBTOdS5Dgs0AOw+vfI3inkXMECUCdc67azC4Ffu+cy29kO1OAKQDp6elDpk2bFrCa5exVV1cTFxcX7DLapDrn2LC/jvnltSzaWcuRWkiPMUbnhDEqO4ykyMBeya2+adtao3/Gjh271DlX2NC6oAVBA223AIXOuT1NtSssLHRLlixpkfqkZRUXF1NUVBTsMtq8IzUn+MfqHUxbXMqizfsIDTEu7tOZ64fmMqZXGmGhLR8K6pu2rTX6x8waDYKgHRoyswxgl3POmdkwfCeu9warHpHWEh0RylWDc7hqcA6bdlfz2pIypi8tY+aaXaQnRHLFoGwuG5BFv6wEHTqSVhHIy0dfAYqAVDMrA34KhAM4554CrgH+zcxqgSPA9U6PixKP6Z4Wx48m9eE/JvTi43UVvLa4lGfnbubPszfRLTWWS/pl8I0BmfTPTgx2qdKBBfKqoRtOs/4J4IlAfb5IexIeGsIl/TK4pF8G+w7V8P7qnby7qpxn527iqdlfUJCZwFWDs/nGgCwyEqOCXa50MMG+akhETpESG8G3hnfhW8O7UHm4hhkrynltSRm/eHctv3xvLRf06MTkgdlM6p9BfFR4sMuVDkBBINKGJcVEcPPIrtw8siubdlfz1vJy3ly+nQemr+Q/31zNuL7pjC9I54Kenegcrz0FOTsKApF2ontaHPeN78W94/L5rLSStz7bzoyVO3h31Q4AeqfHM66gM5f0y+C87ESdaJZmUxCItDNmxuAuyQzuksxDl/WjpLyKeRv3Mmf9bp6avYk/zvqCzMQoJhSkc0m/DIZ1Swl2ydLGKQhE2rHQEGNAThIDcpL4t6Ie7D9Uwz/XVfBByU6mLS7lxQVbSYoJp1+S42jqTsb0SiM6IjTYZUsboyAQ6UCSYyO4ZkgO1wzJ4XBNLXPW7+HDkp28v2o78/66lKjwEMb0SmN8QQaFecnkdYrRISRREIh0VDERYScHwbs0bT8xXc7j/ZKdvL96Jx+U7AKgS0oM4wvSmVCQzpC85IDc1SzB5Zyj8vDxJtsoCEQ8ICzEuKBnKhf0TOVnl/Vj3c6DLN22n3+u3cVfFmzluU82kxgdTpeUGIbkJTOqZyrDu6eQoMtT240TdY5t+w6zYddBNlRUs2HXQTbvOcTmPYc4cLS2yfcqCEQ8JiTEKMhKoCArgZtH5FF9rJbZn+9m9voKSvcdYdribUydv4XQEGNo12Qm9svgwvxUeqTF6TBSG+M7/LebD0p28dHaXRys94WfmRhFj7Q4Lh+YRddOsdzxX41vR0Eg4nFxkWF8fUAmXx+QCcCx2hMs21rJ3A27mblmFz+bsQaA1LhILuzZiRHdO1HYNYXuqbGE6JGcrariwFFKyg+woeIgJeUH+KBkJ0eP15EUE86EggyGd0+hV3o8PdJiv3Kz4R1NbFdBICL/IjIslJE9OjGyRycemNiHzXsOsWjzXuZ/sZdPNu7hzeXlACTFhFOYl8KQvGQG5CTSPyuRxBgdSmoJdXWOrfsO8/nOA6zbeZD1uw6ybqfvUM+XI7KlxkUw+fxsJg/MYli3lHM6v6MgEJEmdUuNpVtqLNcN7YJzji92H2LZ1v0s2bqPRZv38dHaXSfbdu0Uw3k5SfTLSqB/ViIDchN1nuE06uoc5dV1vL2inJLtVawoq2T19gNUH/Md5jGDvJQYemfEc/XgHIZ1S6FnWlyLPg9bQSAizWZm9OwcR8/OcVw7NBeAysM1rNpexcqyKlaVVbF0yz5mrCj3t4ceaXEMyk1iYJckBuYm0Ts93vNXJ5VXHuGt5eXM27iHFaWVHDxWC3xGRGgIfTPjuXJQNudlJ9InM56eneMC/nhTBYGInJOkmAguyk/jovy0k8v2H6ph5fYqlm+rZHnpfj5au4u/LS0DIDo8lPOyE+mVEUfvjATfF15GPFHhvhvdjp+oIyzE2v2J6aPHT7BmxwHW7jjAuh0H2VBxkLL9R9h/qIZDNScA6JMRz+RBWURW7+Tqi4fTs3McEWGtH5IKAhFpccmxEYzplcaYXr5wcM53aePy0ko+21bJ8tJK3l5ezoGj2wDf5a356fGEGHy+8yAAafGRpMVHkpsSQ75/LyS/czxdU2OIDAvu3dHOOU7UOeochJhvT6mmto7KIzWs23mQuev3MH1p6cnLNuMjw8hPj2NIXjJpcZHERYVxxcBsuqbGAlBcvJeCrISg/TwKAhEJODMjr1MseZ1imTwwG/B9mZbtP8Lq7VWs2l7Fmh0HqHNw+0WphJix++AxKg4eY/X2Kt5btePkSdLQECMvJYYeneP+JSDy0+NO7lWc6ujxE5SUV7Hv0HGO1Z7g6PE6qo4c50hNLau3H2B75RH2VB/jWG0d0f5tHD1+gsM1J6itqyMxOoLUON8x+QNHjrP3UA3Hausa/XnDQ43xBelMHphNQWYCOcnRbXoPp1lBYGY9gDLn3DEzKwIGAC855yoDWZyIdFxmRm5KDLkpMUw6L7PJtkePn2DT7kNsqDjIFxXVbKioZmNFNbPWVVBb50uIsBDf+YtuqbHkpsSQkxxNZmI0zjl+/f46Nu0+1OC24yPDGJyXTJ+MeCLDQzhSU4dzjuiIUGIiQgkNCaHqSA17qmswICE6nOSYcBKiwjGDOgfOQWR4CLGRYeR3jqN/diJxke3n7+xmPbzezJYDhUBX4APgbaC3c+7SgFbXgPj4eDdkyJDW/lhphsrKSpKSkoJdhjSgo/aNsxCORyZxPCaVmtjO1MR05nhUErWRiRDyP1/EIccPkbLlY8KP7sfqarG6WkJqjxFSdxzcCYL9t3pr9M/s2bPP+eH1dc65WjO7Evidc+4PZvZZy5UoInLmzNURcXQfEUf3Ebtv/cnlDjgRHsuJiDhqIxOJPFhO2PHq4BXaxjU3CI6b2Q3Ad4DL/MuCcnFw7969KS4uDsZHy2kUFxdTVFQU7DKkAeqbtq01+qepcxTNvU7pVmAk8Evn3GYz6wb8tQVqExGRIGvWHoFzbg1wD4CZJQPxzrlfB7IwERFpHc3aIzCzYjNLMLMUYAXwgpk9FtjSRESkNTT30FCic+4AcBXwgnNuCDAucGWJiEhraW4QhJlZJnAt8E4A6xERkVbW3CB4GN/9A1845xabWXdgQ+DKEhGR1tLck8V/A/5Wb34TcHWgihIRkdbT3JPFOWb2dzOrMLNdZva6meUEujgREQm85h4aegHfsBJZQDYww79MRETaueYGQZpz7gXnXK3/NRVIO92bRESk7WtuEOwxs5vMLNT/ugnYG8jCRESkdTQ3CG7Dd+noTmAHcA2+YSdERKSda1YQOOe2Oecud86lOec6O+euwHdzmYiItHPn8nDM+1usChERCZpzCYJgP8tBRERawLkEwekfbSYiIm1ek3cWm9lBGv7CNyA6IBWJiEiranKPwDkX75xLaOAV75w7XYg8778TeXUj683MHjezjWa20swGn8sPIiIiZ+dcDg2dzlRgYhPrJwH5/tcU4MkA1iIiIo0IWBA45+YA+5poMhl4yfl8CiT5h7oWEZFWFMg9gtPJBkrrzZf5l4mISCtq1jDUAdLQ5acNXolkZlPwHT4iPT2d4uLiAJYlZ6u6ulp900apb9q2YPdPMIOgDMitN58DlDfU0Dn3NPA0QGFhoSsqKgp4cXLmiouLUd+0Teqbti3Y/RPMQ0NvA9/2Xz00Aqhyzu0IYj0iIp4UsD0CM3sFKAJSzawM+CkQDuCcewp4D7gU2AgcRoPYiYgERcCCwDl3w2nWO+CuQH2+iIg0TzAPDYmISBugIBAR8TgFgYiIxykIREQ8TkEgIuJxCgIREY9TEIiIeJyCQETE4xQEIiIepyAQEfE4BYGIiMcpCEREPE5BICLicQoCERGPUxCIiHicgkBExOMUBCIiHqcgEBHxOAWBiIjHKQhERDxOQSAi4nEKAhERj1MQiIh4nIJARMTjFAQiIh6nIBAR8TgFgYiIxykIREQ8TkEgIuJxCgIREY9TEIiIeJyCQETE4xQEIiIepyAQEfE4BYGIiMcpCEREPE5BICLicQoCERGPC2gQmNlEM/vczDaa2Y8aWH+Lme02s+X+13cDWY+IiHxVWKA2bGahwB+B8UAZsNjM3nbOrTml6avOubsDVYeIiDQtkHsEw4CNzrlNzrkaYBowOYCfJyIiZyFgewRANlBab74MGN5Au6vNbDSwHrjPOVd6agMzmwJMAUhPT6e4uLjlq5VzVl1drb5po9Q3bVuw+yeQQWANLHOnzM8AXnHOHTOzO4EXgYu/8ibnngaeBigsLHRFRUUtXKq0hOLiYtQ3bZP6pm0Ldv8E8tBQGZBbbz4HKK/fwDm31zl3zD/7DDAkgPWIiEgDAhkEi4F8M+tmZhHA9cDb9RuYWWa92cuBtQGsR0REGhCwQ0POuVozuxv4AAgFnnfOlZjZw8AS59zbwD1mdjlQC+wDbglUPSIi0rBAniPAOfce8N4pyx6qN/0g8GAgaxARkabpzmIREY9TEIiIeJyCQETE4xQEIiIepyAQEfE4BYGIiMcpCEREPE5BICLicQoCERGPUxCIiHicgkBExOMUBCIiHqcgEBHxOAWBiIjHKQhERDxOQSAi4nEKAhERj1MQiIh4nIJARMTjFAQiIh6nIBAR8TgFgYiIxykIREQ8TkEgIuJxCgIREY9TEIiIeJyCQETE4xQEIiIepyAQEfE4BYGIiMcpCEREPE5BICLicQoCERGPUxCIiHicgkBExOMUBCIiHqcgEBHxuIAGgZlNNLPPzWyjmf2ogfWRZvaqf/1CM+sayHpEROSrAhYEZhYK/BGYBBQAN5hZwSnNbgf2O+d6Av8P+K9A1SMiIg0L5B7BMGCjc26Tc64GmAZMPqXNZOBF//R04GtmZgGsSUREThEWwG1nA6X15suA4Y21cc7VmlkV0AnYU7+RmU0Bpvhnq83s84BUfHqJQFWQttPc95yuXVPrG1vX3OWpnNJ3rail+uZsttVSfdNUG/XN2W/rXH7vzW1zJv3T0LLW6J+8Rtc45wLyAr4JPFtv/mbgD6e0KQFy6s1/AXQKVE0t8DM9HaztNPc9p2vX1PrG1jV3ObCkvffN2WyrpfqmJfpAfdOyv/fmtjmT/mlkWdD6xzkX0ENDZUBuvfkcoLyxNmYWhi8p9wWwpnM1I4jbae57TteuqfWNrTvT5cHQkrWc6bZaqm+aaqO+OfttncvvvbltzqQf2lLfAGD+NGr5Dfu+2NcDXwO2A4uBbznnSuq1uQs4zzl3p5ldD1zlnLs2IAVJwJnZEudcYbDrkK9S37Rtwe6fgJ0jcL5j/ncDHwChwPPOuRIzexjfbtDbwHPAX8xsI749gesDVY+0iqeDXYA0Sn3TtgW1fwK2RyAiIu2D7iwWEfE4BYGIiMcpCEREPE5BIK3CzK4ws2fM7C0zmxDseuR/mFl3M3vOzKYHuxYBM4s1sxf9/15ubI3PVBDIaZnZ82ZWYWarT1ne5KCC9Tnn3nTO3QHcAlwXwHI9pYX6ZpNz7vbAVuptZ9hPVwHT/f9eLm+N+hQE0hxTgYn1FzQ2qKCZnWdm75zy6lzvrT/xv09axlRarm8kcKbSzH7Cd/Ptl8PznGiN4gI51pB0EM65OQ0MEX5yUEEAM5sGTHbO/Qr4xqnb8A8m+GvgH865ZYGt2Dtaom8k8M6kn/CNuJADLKeV/ljXHoGcrYYGFcxuov3/BsYB15jZnYEsTM6sb8ysk5k9BQwyswcDXZyc1Fg/vQFcbWZP0krDUWiPQM5WQ8OFN3p3onPuceDxwJUj9Zxp3+wFFM6tr8F+cs4dAm5tzUK0RyBnqzmDCkpwqG/ahzbTTwoCOVuLgXwz62ZmEfjGiXo7yDWJj/qmfWgz/aQgkNMys1eABUBvMyszs9udc7XAl4MKrgVeqz+yrLQO9U370Nb7SYPOiYh4nPYIREQ8TkEgIuJxCgIREY9TEIiIeJyCQETE4xQEIiIepyCQDsPMqlv58571jxbZmp95r5nFtOZnSsen+wikwzCzao9Ahx8AAAK1SURBVOdcXAtuL8x/00+r8Y/Sas65ukbWbwEKnXN7WrMu6di0RyAdmpmlmdnrZrbY/xrlXz7MzOab2Wf+//b2L7/FzP5mZjOAD82syMyKzWy6ma0zs//2f1njX17on642s1+a2Qoz+9TM0v3Le/jnF5vZww3ttZhZVzNba2Z/ApYBuWb2pJktMbMSM/u5v909QBYwy8xm+ZdNMLMFZrbMX3eLBaF4iHNOL706xAuobmDZy8CF/ukuwFr/dAIQ5p8eB7zun74F32BgKf75IqAK34BgIfiGCfhye8X4/joH3+iel/mnHwF+4p9+B7jBP31nIzV2BeqAEfWWffn5of7PGeCf3wKk+qdTgTlArH/+h8BDwe4HvdrfS8NQS0c3Dijw/xEPkGBm8UAi8KKZ5eP7Eg+v956Zzrl99eYXOefKAMxsOb4v7k9O+ZwafF/6AEuB8f7pkcAV/umXgUcbqXOrc+7TevPXmtkUfEPFZ+J7gtXKU94zwr98nv/ni8AXVCJnREEgHV0IMNI5d6T+QjP7AzDLOXel/8lRxfVWHzplG8fqTZ+g4X83x51z7jRtmnLyM82sG/B9YKhzbr+ZTQWiGniP4QutG87ws0T+hc4RSEf3Ib4RHgEws4H+yURgu3/6lgB+/qfA1f7p65v5ngR8wVDlP9cwqd66g0B8vW2PMrOeAGYWY2a9zr1k8RoFgXQkMf4hfr983Q/cAxSa2UozW8P/PInrEeBXZjYP33H4QLkXuN/MFuE7xFN1ujc451YAnwElwPPAvHqrnwb+YWaznHO78YXYK2a2El8w9GnZ8sULdPmoSAD5r/k/4pxzZnY9vhPHk4Ndl0h9OkcgElhDgCf8l5xWArcFuR6Rr9AegYiIx+kcgYiIxykIREQ8TkEgIuJxCgIREY9TEIiIeJyCQETE4/4/EsENB1HsNjkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> In general, the optimal learning rate is about half of the maximum learning rate, thats mean is, when learning rate did minimize loss function, half of this lr is the best. \n",
    "\n",
    "So in here, 10^-1= 3e-1 close to the best. I will use it.\n",
    "\n",
    "Now, i will try 3e-1 learning rate and took if there is a different on test set or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6838 - accuracy: 0.7449 - val_loss: 0.5725 - val_accuracy: 0.7909\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4727 - accuracy: 0.8285 - val_loss: 0.6079 - val_accuracy: 0.7731\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4322 - accuracy: 0.8420 - val_loss: 0.4225 - val_accuracy: 0.8493\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4057 - accuracy: 0.8509 - val_loss: 0.4101 - val_accuracy: 0.8511\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3905 - accuracy: 0.8559 - val_loss: 0.4608 - val_accuracy: 0.8411\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3817 - accuracy: 0.8597 - val_loss: 0.4039 - val_accuracy: 0.8508\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3700 - accuracy: 0.8640 - val_loss: 0.4203 - val_accuracy: 0.8481\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3617 - accuracy: 0.8663 - val_loss: 0.3952 - val_accuracy: 0.8591\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3514 - accuracy: 0.8716 - val_loss: 0.3736 - val_accuracy: 0.8667\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3446 - accuracy: 0.8721 - val_loss: 0.3986 - val_accuracy: 0.8643\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3392 - accuracy: 0.8745 - val_loss: 0.4075 - val_accuracy: 0.8579\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3330 - accuracy: 0.8771 - val_loss: 0.3894 - val_accuracy: 0.8633\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3303 - accuracy: 0.8770 - val_loss: 0.3837 - val_accuracy: 0.8687\n",
      "Epoch 14/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3231 - accuracy: 0.8806 - val_loss: 0.3839 - val_accuracy: 0.8667\n",
      "Epoch 15/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3186 - accuracy: 0.8808 - val_loss: 0.3664 - val_accuracy: 0.8719\n",
      "Epoch 16/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3168 - accuracy: 0.8824 - val_loss: 0.4348 - val_accuracy: 0.8496\n",
      "Epoch 17/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8841 - val_loss: 0.3627 - val_accuracy: 0.8755\n",
      "Epoch 18/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3073 - accuracy: 0.8869 - val_loss: 0.3607 - val_accuracy: 0.8765\n",
      "Epoch 19/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3036 - accuracy: 0.8875 - val_loss: 0.4454 - val_accuracy: 0.8443\n",
      "Epoch 20/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3020 - accuracy: 0.8870 - val_loss: 0.3749 - val_accuracy: 0.8745\n",
      "Epoch 21/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2990 - accuracy: 0.8881 - val_loss: 0.3863 - val_accuracy: 0.8725\n",
      "Epoch 22/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2930 - accuracy: 0.8903 - val_loss: 0.4064 - val_accuracy: 0.8602\n",
      "Epoch 23/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2922 - accuracy: 0.8898 - val_loss: 0.3827 - val_accuracy: 0.8728\n",
      "Epoch 24/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2876 - accuracy: 0.8908 - val_loss: 0.4093 - val_accuracy: 0.8597\n",
      "Epoch 25/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2827 - accuracy: 0.8939 - val_loss: 0.3903 - val_accuracy: 0.8678\n",
      "Epoch 26/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2870 - accuracy: 0.8939 - val_loss: 0.3831 - val_accuracy: 0.8729\n",
      "Epoch 27/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2779 - accuracy: 0.8943 - val_loss: 0.3901 - val_accuracy: 0.8711\n",
      "Epoch 28/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2805 - accuracy: 0.8952 - val_loss: 0.4239 - val_accuracy: 0.8542\n",
      "Epoch 29/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2761 - accuracy: 0.8969 - val_loss: 0.3920 - val_accuracy: 0.8712\n",
      "Epoch 30/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2747 - accuracy: 0.8960 - val_loss: 0.3985 - val_accuracy: 0.8754\n",
      "Epoch 31/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2721 - accuracy: 0.8986 - val_loss: 0.4221 - val_accuracy: 0.8652\n",
      "Epoch 32/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2716 - accuracy: 0.8982 - val_loss: 0.4111 - val_accuracy: 0.8729\n",
      "Epoch 33/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2675 - accuracy: 0.9007 - val_loss: 0.3858 - val_accuracy: 0.8764\n",
      "Epoch 34/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2669 - accuracy: 0.8997 - val_loss: 0.4713 - val_accuracy: 0.8574\n",
      "Epoch 35/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2848 - accuracy: 0.8957 - val_loss: 0.3829 - val_accuracy: 0.8748\n",
      "Epoch 36/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2672 - accuracy: 0.9005 - val_loss: 0.4410 - val_accuracy: 0.8651\n",
      "Epoch 37/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2652 - accuracy: 0.9016 - val_loss: 0.4207 - val_accuracy: 0.8723\n",
      "Epoch 38/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2590 - accuracy: 0.9036 - val_loss: 0.4044 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "model=model_()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=3e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 985us/step - loss: 0.2507 - accuracy: 0.9047\n",
      "Train      [0.2506762146949768, 0.9046875238418579]\n",
      "375/375 [==============================] - 0s 953us/step - loss: 0.4044 - accuracy: 0.8702\n",
      "Validation [0.4043923020362854, 0.8701666593551636]\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4255 - accuracy: 0.8658\n",
      "Test       [0.42553281784057617, 0.8658000230789185]\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got less accuracy. Sometimes it could be. But this shouldnt may couse you give up from this tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now... Let's try other hyperparameter sets. We can do this in multiple ways. \n",
    "\n",
    "First: \n",
    "\n",
    "***GridSearchCV:*** This way does not make GPU acceleration. That's bad. \n",
    "\n",
    "***Hyperas:*** This way enable GPU acceleration. And enabling 10x fast and also easyer than GridSearch. \n",
    "\n",
    "I will apply GridSeachCV first, than apply Hyperas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.6279 - accuracy: 0.3110 - val_loss: 1.3649 - val_accuracy: 0.4055\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 2.0885 - accuracy: 0.1740 - val_loss: 2.3040 - val_accuracy: 0.1004\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3051 - accuracy: 0.0990 - val_loss: 2.3042 - val_accuracy: 0.1002\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3049 - accuracy: 0.0990 - val_loss: 2.3053 - val_accuracy: 0.1002\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 2.3049 - accuracy: 0.0990 - val_loss: 2.3044 - val_accuracy: 0.1002\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.3049 - accuracy: 0.1011 - val_loss: 2.3040 - val_accuracy: 0.0966\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.2372 - accuracy: 0.5286 - val_loss: 0.9557 - val_accuracy: 0.5891\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8568 - accuracy: 0.6667 - val_loss: 0.9771 - val_accuracy: 0.6207\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8149 - accuracy: 0.6830 - val_loss: 1.3890 - val_accuracy: 0.4892\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8137 - accuracy: 0.6822 - val_loss: 0.7692 - val_accuracy: 0.7021\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7818 - accuracy: 0.6952 - val_loss: 0.9283 - val_accuracy: 0.6695\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.2489 - accuracy: 0.5299 - val_loss: 1.9689 - val_accuracy: 0.2262\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7063 - accuracy: 0.2879 - val_loss: 1.4366 - val_accuracy: 0.3511\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7582 - accuracy: 0.2401 - val_loss: 1.4692 - val_accuracy: 0.3520\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3143 - accuracy: 0.4277 - val_loss: 1.2086 - val_accuracy: 0.4470\n",
      "500/500 [==============================] - 0s 860us/step - loss: 1.1965 - accuracy: 0.4536\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1877 - accuracy: 0.5222 - val_loss: 1.0515 - val_accuracy: 0.5630\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0017 - accuracy: 0.5788 - val_loss: 1.1197 - val_accuracy: 0.5620\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0337 - accuracy: 0.5527 - val_loss: 1.0450 - val_accuracy: 0.5263\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0602 - accuracy: 0.5354 - val_loss: 1.0105 - val_accuracy: 0.5485\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9790 - accuracy: 0.5907 - val_loss: 1.5445 - val_accuracy: 0.4701\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9522 - accuracy: 0.5938 - val_loss: 0.8842 - val_accuracy: 0.6117\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9707 - accuracy: 0.5890 - val_loss: 1.0299 - val_accuracy: 0.5200\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0365 - accuracy: 0.5459 - val_loss: 0.9951 - val_accuracy: 0.5642\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0145 - accuracy: 0.5473 - val_loss: 0.9708 - val_accuracy: 0.5443\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0072 - accuracy: 0.5576 - val_loss: 1.0438 - val_accuracy: 0.5416\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0891 - accuracy: 0.5253 - val_loss: 1.0170 - val_accuracy: 0.5512\n",
      "500/500 [==============================] - 0s 795us/step - loss: 1.0034 - accuracy: 0.5574\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 2ms/step - loss: 1.2038 - accuracy: 0.5300 - val_loss: 0.7845 - val_accuracy: 0.6973\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 994us/step - loss: 0.7906 - accuracy: 0.6868 - val_loss: 0.7428 - val_accuracy: 0.7006\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7931 - accuracy: 0.6895 - val_loss: 0.7451 - val_accuracy: 0.7040 loss: 0.8086 - ac\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7248 - accuracy: 0.7135 - val_loss: 0.7093 - val_accuracy: 0.7193\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7129 - accuracy: 0.7143 - val_loss: 1.4211 - val_accuracy: 0.5941\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7607 - accuracy: 0.6958 - val_loss: 0.7096 - val_accuracy: 0.7087\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8904 - accuracy: 0.6359 - val_loss: 1.2369 - val_accuracy: 0.5502\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1312 - accuracy: 0.5167 - val_loss: 1.2238 - val_accuracy: 0.4572\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.2573 - accuracy: 0.4898 - val_loss: 1.5469 - val_accuracy: 0.3624\n",
      "500/500 [==============================] - 0s 773us/step - loss: 1.5366 - accuracy: 0.3623\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 2ms/step - loss: 0.8578 - accuracy: 0.6604 - val_loss: 0.7138 - val_accuracy: 0.7096\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5968 - accuracy: 0.7736 - val_loss: 0.5546 - val_accuracy: 0.7943\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.8089 - val_loss: 0.5304 - val_accuracy: 0.8140\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4918 - accuracy: 0.8284 - val_loss: 0.4811 - val_accuracy: 0.8378\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4668 - accuracy: 0.8375 - val_loss: 0.4964 - val_accuracy: 0.8270\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4541 - accuracy: 0.8410 - val_loss: 0.4536 - val_accuracy: 0.8414\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4444 - accuracy: 0.8441 - val_loss: 0.4561 - val_accuracy: 0.8367\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4327 - accuracy: 0.8496 - val_loss: 0.4939 - val_accuracy: 0.8374\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4266 - accuracy: 0.8513 - val_loss: 0.4552 - val_accuracy: 0.8418\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4208 - accuracy: 0.8525 - val_loss: 0.4650 - val_accuracy: 0.8381\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4131 - accuracy: 0.8546 - val_loss: 0.4477 - val_accuracy: 0.8438\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4099 - accuracy: 0.8560 - val_loss: 0.4405 - val_accuracy: 0.8467\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4060 - accuracy: 0.8580 - val_loss: 0.4440 - val_accuracy: 0.8538\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4049 - accuracy: 0.8581 - val_loss: 0.4717 - val_accuracy: 0.8440\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8589 - val_loss: 0.4381 - val_accuracy: 0.8538\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8614 - val_loss: 0.4578 - val_accuracy: 0.8480\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8620 - val_loss: 0.4811 - val_accuracy: 0.8355\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8635 - val_loss: 0.4295 - val_accuracy: 0.8538\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8642 - val_loss: 0.4603 - val_accuracy: 0.8468\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8632 - val_loss: 0.4447 - val_accuracy: 0.8500\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8643 - val_loss: 0.4428 - val_accuracy: 0.8470\n",
      "Epoch 22/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3793 - accuracy: 0.8629 - val_loss: 0.4535 - val_accuracy: 0.8504\n",
      "Epoch 23/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3786 - accuracy: 0.8651 - val_loss: 0.4283 - val_accuracy: 0.8568\n",
      "Epoch 24/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3795 - accuracy: 0.8661 - val_loss: 0.4459 - val_accuracy: 0.8461\n",
      "Epoch 25/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8687 - val_loss: 0.4287 - val_accuracy: 0.8564\n",
      "Epoch 26/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3752 - accuracy: 0.8701 - val_loss: 0.4522 - val_accuracy: 0.8508\n",
      "Epoch 27/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3706 - accuracy: 0.8694 - val_loss: 0.4526 - val_accuracy: 0.8489\n",
      "Epoch 28/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3616 - accuracy: 0.8714 - val_loss: 0.4797 - val_accuracy: 0.8447\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4737 - accuracy: 0.8512\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8486 - accuracy: 0.6786 - val_loss: 0.6135 - val_accuracy: 0.7700\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5825 - accuracy: 0.7873 - val_loss: 0.6473 - val_accuracy: 0.7822\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.8056 - val_loss: 0.5473 - val_accuracy: 0.7989\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5071 - accuracy: 0.8184 - val_loss: 0.5020 - val_accuracy: 0.8230\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4840 - accuracy: 0.8249 - val_loss: 0.4617 - val_accuracy: 0.8358\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4665 - accuracy: 0.8314 - val_loss: 0.5080 - val_accuracy: 0.8256\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4585 - accuracy: 0.8367 - val_loss: 0.5100 - val_accuracy: 0.8170\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4477 - accuracy: 0.8396 - val_loss: 0.5160 - val_accuracy: 0.8223\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4397 - accuracy: 0.8440 - val_loss: 0.5348 - val_accuracy: 0.8198\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4320 - accuracy: 0.8465 - val_loss: 0.4764 - val_accuracy: 0.8343\n",
      "500/500 [==============================] - 0s 867us/step - loss: 0.4676 - accuracy: 0.8342\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0514 - accuracy: 0.5866 - val_loss: 0.7108 - val_accuracy: 0.7265\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6900 - accuracy: 0.7289 - val_loss: 0.6369 - val_accuracy: 0.7461\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6070 - accuracy: 0.7750 - val_loss: 0.5920 - val_accuracy: 0.7981\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.8055 - val_loss: 0.5247 - val_accuracy: 0.7875\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.8150 - val_loss: 0.5085 - val_accuracy: 0.8116\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.8246 - val_loss: 0.4925 - val_accuracy: 0.8223\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4701 - accuracy: 0.8329 - val_loss: 0.4979 - val_accuracy: 0.8273\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4541 - accuracy: 0.8388 - val_loss: 0.4636 - val_accuracy: 0.8371\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4458 - accuracy: 0.8411 - val_loss: 0.5707 - val_accuracy: 0.8207\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4312 - accuracy: 0.8453 - val_loss: 0.4813 - val_accuracy: 0.8265\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4276 - accuracy: 0.8466 - val_loss: 0.4538 - val_accuracy: 0.8468\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4229 - accuracy: 0.8475 - val_loss: 0.4920 - val_accuracy: 0.8306\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4160 - accuracy: 0.8485 - val_loss: 0.4889 - val_accuracy: 0.8357\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4112 - accuracy: 0.8538 - val_loss: 0.5968 - val_accuracy: 0.8020\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4052 - accuracy: 0.8522 - val_loss: 0.4707 - val_accuracy: 0.8307\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8561 - val_loss: 0.5056 - val_accuracy: 0.8292\n",
      "500/500 [==============================] - 0s 846us/step - loss: 0.5087 - accuracy: 0.8268\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0353 - accuracy: 0.5999 - val_loss: 0.7002 - val_accuracy: 0.6985\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6044 - accuracy: 0.7771 - val_loss: 0.5510 - val_accuracy: 0.8088\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.8042 - val_loss: 0.5845 - val_accuracy: 0.7958\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4973 - accuracy: 0.8227 - val_loss: 0.4730 - val_accuracy: 0.8332\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.8310 - val_loss: 0.4829 - val_accuracy: 0.8275\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4597 - accuracy: 0.8357 - val_loss: 0.4705 - val_accuracy: 0.8282\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4371 - accuracy: 0.8439 - val_loss: 0.4871 - val_accuracy: 0.8145\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4340 - accuracy: 0.8446 - val_loss: 0.4352 - val_accuracy: 0.8427\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4227 - accuracy: 0.8474 - val_loss: 0.4649 - val_accuracy: 0.8388\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4118 - accuracy: 0.8528 - val_loss: 0.4183 - val_accuracy: 0.8545\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8558 - val_loss: 0.4403 - val_accuracy: 0.8433\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3908 - accuracy: 0.8579 - val_loss: 0.4365 - val_accuracy: 0.8438\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3866 - accuracy: 0.8578 - val_loss: 0.4463 - val_accuracy: 0.8435\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8608 - val_loss: 0.4125 - val_accuracy: 0.8551\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8629 - val_loss: 0.4573 - val_accuracy: 0.8360\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3695 - accuracy: 0.8673 - val_loss: 0.4076 - val_accuracy: 0.8592\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8675 - val_loss: 0.4163 - val_accuracy: 0.8570\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8650 - val_loss: 0.4554 - val_accuracy: 0.8341\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8688 - val_loss: 0.4306 - val_accuracy: 0.8558\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3592 - accuracy: 0.8692 - val_loss: 0.4254 - val_accuracy: 0.8531\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3497 - accuracy: 0.8718 - val_loss: 0.4337 - val_accuracy: 0.8496\n",
      "500/500 [==============================] - 0s 949us/step - loss: 0.4299 - accuracy: 0.8535\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 2ms/step - loss: 1.0511 - accuracy: 0.5867 - val_loss: 0.6330 - val_accuracy: 0.7482\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6314 - accuracy: 0.7563 - val_loss: 0.6027 - val_accuracy: 0.7941\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.8061 - val_loss: 0.5531 - val_accuracy: 0.7974\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4898 - accuracy: 0.8255 - val_loss: 0.4844 - val_accuracy: 0.8300\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4573 - accuracy: 0.8371 - val_loss: 0.4609 - val_accuracy: 0.8338\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.8437 - val_loss: 0.4970 - val_accuracy: 0.8109\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.8444 - val_loss: 0.4423 - val_accuracy: 0.8422\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4096 - accuracy: 0.8538 - val_loss: 0.4399 - val_accuracy: 0.8371\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4047 - accuracy: 0.8546 - val_loss: 0.4302 - val_accuracy: 0.8528\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3919 - accuracy: 0.8610 - val_loss: 0.4095 - val_accuracy: 0.8568\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3822 - accuracy: 0.8619 - val_loss: 0.4800 - val_accuracy: 0.8342\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3844 - accuracy: 0.8608 - val_loss: 0.4007 - val_accuracy: 0.8562\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8615 - val_loss: 0.4316 - val_accuracy: 0.8461\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3671 - accuracy: 0.8663 - val_loss: 0.4202 - val_accuracy: 0.8523\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3612 - accuracy: 0.8669 - val_loss: 0.4513 - val_accuracy: 0.8396\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3597 - accuracy: 0.8700 - val_loss: 0.4143 - val_accuracy: 0.8574\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8699 - val_loss: 0.4222 - val_accuracy: 0.8508\n",
      "500/500 [==============================] - 0s 799us/step - loss: 0.4192 - accuracy: 0.8528\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0616 - accuracy: 0.5910 - val_loss: 0.7350 - val_accuracy: 0.6979\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6765 - accuracy: 0.7358 - val_loss: 0.6239 - val_accuracy: 0.7632\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5717 - accuracy: 0.7888 - val_loss: 0.5368 - val_accuracy: 0.8081\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.8026 - val_loss: 0.5588 - val_accuracy: 0.7997\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5140 - accuracy: 0.8174 - val_loss: 0.5113 - val_accuracy: 0.8179\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5111 - accuracy: 0.8187 - val_loss: 0.5074 - val_accuracy: 0.8152\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.8257 - val_loss: 0.5380 - val_accuracy: 0.8196\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4718 - accuracy: 0.8314 - val_loss: 0.6119 - val_accuracy: 0.7851\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4653 - accuracy: 0.8361 - val_loss: 0.5544 - val_accuracy: 0.8164\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4485 - accuracy: 0.8387 - val_loss: 0.4815 - val_accuracy: 0.8286\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4364 - accuracy: 0.8453 - val_loss: 0.4696 - val_accuracy: 0.8388\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4190 - accuracy: 0.8485 - val_loss: 0.5044 - val_accuracy: 0.8186\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4161 - accuracy: 0.8527 - val_loss: 0.4802 - val_accuracy: 0.8417\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8577 - val_loss: 0.4535 - val_accuracy: 0.8448\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8576 - val_loss: 0.4474 - val_accuracy: 0.8428\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3968 - accuracy: 0.8583 - val_loss: 0.4678 - val_accuracy: 0.8457\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3865 - accuracy: 0.8608 - val_loss: 0.4728 - val_accuracy: 0.8403\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3819 - accuracy: 0.8614 - val_loss: 0.4466 - val_accuracy: 0.8416\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8641 - val_loss: 0.4389 - val_accuracy: 0.8493\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3760 - accuracy: 0.8658 - val_loss: 0.4277 - val_accuracy: 0.8542\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3753 - accuracy: 0.8646 - val_loss: 0.4636 - val_accuracy: 0.8339\n",
      "Epoch 22/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8623 - val_loss: 0.5312 - val_accuracy: 0.8150\n",
      "Epoch 23/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8713 - val_loss: 0.4250 - val_accuracy: 0.8516\n",
      "Epoch 24/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3597 - accuracy: 0.8712 - val_loss: 0.4456 - val_accuracy: 0.8352\n",
      "Epoch 25/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3559 - accuracy: 0.8707 - val_loss: 0.4407 - val_accuracy: 0.8502\n",
      "Epoch 26/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3504 - accuracy: 0.8730 - val_loss: 0.4518 - val_accuracy: 0.8509\n",
      "Epoch 27/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.8752 - val_loss: 0.4095 - val_accuracy: 0.8597\n",
      "Epoch 28/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3440 - accuracy: 0.8757 - val_loss: 0.4584 - val_accuracy: 0.8445\n",
      "Epoch 29/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3438 - accuracy: 0.8763 - val_loss: 0.4212 - val_accuracy: 0.8583\n",
      "Epoch 30/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3403 - accuracy: 0.8765 - val_loss: 0.4128 - val_accuracy: 0.8581\n",
      "Epoch 31/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3454 - accuracy: 0.8755 - val_loss: 0.4259 - val_accuracy: 0.8533\n",
      "Epoch 32/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3412 - accuracy: 0.8777 - val_loss: 0.4173 - val_accuracy: 0.8585\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4171 - accuracy: 0.8556\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3031 - accuracy: 0.4674 - val_loss: 0.9655 - val_accuracy: 0.6303\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8629 - accuracy: 0.6548 - val_loss: 0.8376 - val_accuracy: 0.6570\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7385 - accuracy: 0.6983 - val_loss: 0.7230 - val_accuracy: 0.6902\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9520 - accuracy: 0.6108 - val_loss: 0.9598 - val_accuracy: 0.6093\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.9219 - accuracy: 0.5002 - val_loss: 1.6277 - val_accuracy: 0.2864\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 996us/step - loss: 1.3844 - accuracy: 0.3575 - val_loss: 1.4279 - val_accuracy: 0.2869\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7284 - accuracy: 0.2239 - val_loss: 1.7330 - val_accuracy: 0.1983\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7193 - accuracy: 0.2155 - val_loss: 1.7491 - val_accuracy: 0.2048\n",
      "500/500 [==============================] - 0s 672us/step - loss: 1.7494 - accuracy: 0.2009\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6127 - accuracy: 0.2805 - val_loss: 1.6702 - val_accuracy: 0.2230\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5023 - accuracy: 0.3233 - val_loss: 1.3398 - val_accuracy: 0.4692\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5373 - accuracy: 0.3846 - val_loss: 1.5169 - val_accuracy: 0.2921\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5537 - accuracy: 0.2764 - val_loss: 1.5200 - val_accuracy: 0.2900\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4959 - accuracy: 0.2814 - val_loss: 1.4642 - val_accuracy: 0.2932\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5118 - accuracy: 0.2828 - val_loss: 1.4742 - val_accuracy: 0.2894\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4638 - accuracy: 0.2904 - val_loss: 1.4583 - val_accuracy: 0.2887\n",
      "500/500 [==============================] - 0s 638us/step - loss: 1.4512 - accuracy: 0.2865\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6642 - accuracy: 0.2806 - val_loss: 1.7158 - val_accuracy: 0.1982\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7707 - accuracy: 0.2136 - val_loss: 1.7640 - val_accuracy: 0.1892\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.0154 - accuracy: 0.1496 - val_loss: 2.3058 - val_accuracy: 0.1002\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3142 - accuracy: 0.1026 - val_loss: 2.3230 - val_accuracy: 0.0997\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3134 - accuracy: 0.1009 - val_loss: 2.3086 - val_accuracy: 0.0997\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3120 - accuracy: 0.0990 - val_loss: 2.3128 - val_accuracy: 0.0997\n",
      "500/500 [==============================] - 0s 886us/step - loss: 2.3131 - accuracy: 0.0978\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 1.0620 - accuracy: 0.5695 - val_loss: 0.7612 - val_accuracy: 0.6721\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6739 - accuracy: 0.7218 - val_loss: 0.6169 - val_accuracy: 0.7494\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6155 - accuracy: 0.7463 - val_loss: 0.6077 - val_accuracy: 0.7408\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5941 - accuracy: 0.7643 - val_loss: 0.5759 - val_accuracy: 0.7676\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5550 - accuracy: 0.7824 - val_loss: 0.6824 - val_accuracy: 0.7640\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7859 - val_loss: 0.5589 - val_accuracy: 0.7780\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7929 - val_loss: 0.5658 - val_accuracy: 0.7926\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5099 - accuracy: 0.7997 - val_loss: 0.5313 - val_accuracy: 0.8016\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5029 - accuracy: 0.8071 - val_loss: 0.5176 - val_accuracy: 0.8102\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4867 - accuracy: 0.8225 - val_loss: 0.4913 - val_accuracy: 0.8214\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4741 - accuracy: 0.8280 - val_loss: 0.5293 - val_accuracy: 0.8127\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4734 - accuracy: 0.8297 - val_loss: 0.4684 - val_accuracy: 0.8373\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4591 - accuracy: 0.8374 - val_loss: 0.4864 - val_accuracy: 0.8299\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.8367 - val_loss: 0.4970 - val_accuracy: 0.8197\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4521 - accuracy: 0.8398 - val_loss: 0.4818 - val_accuracy: 0.8335\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4365 - accuracy: 0.8456 - val_loss: 0.4655 - val_accuracy: 0.8452\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4400 - accuracy: 0.8440 - val_loss: 0.4780 - val_accuracy: 0.8273\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4351 - accuracy: 0.8451 - val_loss: 0.4809 - val_accuracy: 0.8375\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4325 - accuracy: 0.8452 - val_loss: 0.5487 - val_accuracy: 0.8162\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4191 - accuracy: 0.8499 - val_loss: 0.4618 - val_accuracy: 0.8443\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4294 - accuracy: 0.8492 - val_loss: 0.4914 - val_accuracy: 0.8201\n",
      "Epoch 22/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.8448 - val_loss: 0.5458 - val_accuracy: 0.8241\n",
      "Epoch 23/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4675 - accuracy: 0.8346 - val_loss: 0.4849 - val_accuracy: 0.8307\n",
      "Epoch 24/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4191 - accuracy: 0.8501 - val_loss: 0.4604 - val_accuracy: 0.8435\n",
      "Epoch 25/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4343 - accuracy: 0.8509 - val_loss: 0.4610 - val_accuracy: 0.8512\n",
      "Epoch 26/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4075 - accuracy: 0.8564 - val_loss: 0.5189 - val_accuracy: 0.8414\n",
      "Epoch 27/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4223 - accuracy: 0.8499 - val_loss: 0.4562 - val_accuracy: 0.8444\n",
      "Epoch 28/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8565 - val_loss: 0.4394 - val_accuracy: 0.8489\n",
      "Epoch 29/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8577 - val_loss: 0.4668 - val_accuracy: 0.8464\n",
      "Epoch 30/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4162 - accuracy: 0.8533 - val_loss: 0.5459 - val_accuracy: 0.8181\n",
      "Epoch 31/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8577 - val_loss: 0.4466 - val_accuracy: 0.8433\n",
      "Epoch 32/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8577 - val_loss: 0.4800 - val_accuracy: 0.8405\n",
      "Epoch 33/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3932 - accuracy: 0.8587 - val_loss: 0.4644 - val_accuracy: 0.8426\n",
      "500/500 [==============================] - 1s 996us/step - loss: 0.4468 - accuracy: 0.8468\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1706 - accuracy: 0.5297 - val_loss: 0.8237 - val_accuracy: 0.6604\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7739 - accuracy: 0.6829 - val_loss: 0.6785 - val_accuracy: 0.7170\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6819 - accuracy: 0.7155 - val_loss: 0.6663 - val_accuracy: 0.7132\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6419 - accuracy: 0.7300 - val_loss: 0.6541 - val_accuracy: 0.7263\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6688 - accuracy: 0.7324 - val_loss: 0.6057 - val_accuracy: 0.7763\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5932 - accuracy: 0.7745 - val_loss: 0.5836 - val_accuracy: 0.7657\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5680 - accuracy: 0.7863 - val_loss: 0.5554 - val_accuracy: 0.7955\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.7902 - val_loss: 0.5673 - val_accuracy: 0.7887\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7942 - val_loss: 0.5643 - val_accuracy: 0.7934\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7973 - val_loss: 0.5569 - val_accuracy: 0.7936\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.8016 - val_loss: 0.5190 - val_accuracy: 0.8197\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5195 - accuracy: 0.8230 - val_loss: 0.5114 - val_accuracy: 0.8263\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.8289 - val_loss: 0.5044 - val_accuracy: 0.8324\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4838 - accuracy: 0.8364 - val_loss: 0.5226 - val_accuracy: 0.8358\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4689 - accuracy: 0.8418 - val_loss: 0.5580 - val_accuracy: 0.7974\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4725 - accuracy: 0.8408 - val_loss: 0.4888 - val_accuracy: 0.8371\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4686 - accuracy: 0.8405 - val_loss: 0.5142 - val_accuracy: 0.8352\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.8432 - val_loss: 0.5493 - val_accuracy: 0.8132\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4643 - accuracy: 0.8438 - val_loss: 0.5012 - val_accuracy: 0.8374\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.8458 - val_loss: 0.4890 - val_accuracy: 0.8342\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8445 - val_loss: 0.4911 - val_accuracy: 0.8363\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4732 - accuracy: 0.8409\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 4s 3ms/step - loss: 1.0347 - accuracy: 0.5887 - val_loss: 0.7161 - val_accuracy: 0.7075\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6943 - accuracy: 0.7278 - val_loss: 0.6768 - val_accuracy: 0.7233\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7026 - accuracy: 0.7320 - val_loss: 0.6448 - val_accuracy: 0.7279\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6040 - accuracy: 0.7662 - val_loss: 0.6005 - val_accuracy: 0.7849\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6028 - accuracy: 0.7767 - val_loss: 0.5459 - val_accuracy: 0.8003\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.8018 - val_loss: 0.5643 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5184 - accuracy: 0.8134 - val_loss: 0.5878 - val_accuracy: 0.8013\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5042 - accuracy: 0.8188 - val_loss: 0.4882 - val_accuracy: 0.8245\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5001 - accuracy: 0.8185 - val_loss: 0.5233 - val_accuracy: 0.8108\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.8282 - val_loss: 0.5346 - val_accuracy: 0.8094\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8295 - val_loss: 0.4980 - val_accuracy: 0.8277\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.8275\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4607 - accuracy: 0.8362 - val_loss: 0.5005 - val_accuracy: 0.8048\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4571 - accuracy: 0.8380 - val_loss: 0.4811 - val_accuracy: 0.8303\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4583 - accuracy: 0.8377 - val_loss: 0.5196 - val_accuracy: 0.8077\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8433 - val_loss: 0.4967 - val_accuracy: 0.8296\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8442 - val_loss: 0.5505 - val_accuracy: 0.8106\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4677 - accuracy: 0.8363 - val_loss: 0.5711 - val_accuracy: 0.7936\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4694 - accuracy: 0.8366 - val_loss: 0.5298 - val_accuracy: 0.8174\n",
      "500/500 [==============================] - 0s 960us/step - loss: 0.5275 - accuracy: 0.8188\n",
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9436 - accuracy: 0.6306 - val_loss: 0.6329 - val_accuracy: 0.7308\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5789 - accuracy: 0.7821 - val_loss: 0.6549 - val_accuracy: 0.7720\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5124 - accuracy: 0.8149 - val_loss: 0.5193 - val_accuracy: 0.8145\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4775 - accuracy: 0.8283 - val_loss: 0.4614 - val_accuracy: 0.8404\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4471 - accuracy: 0.8387 - val_loss: 0.4705 - val_accuracy: 0.8280\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4313 - accuracy: 0.8426 - val_loss: 0.4480 - val_accuracy: 0.8328\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4198 - accuracy: 0.8476 - val_loss: 0.4474 - val_accuracy: 0.8417\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4118 - accuracy: 0.8512 - val_loss: 0.4164 - val_accuracy: 0.8489\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4006 - accuracy: 0.8560 - val_loss: 0.4766 - val_accuracy: 0.8257\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3933 - accuracy: 0.8567 - val_loss: 0.4295 - val_accuracy: 0.8527\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3932 - accuracy: 0.8581 - val_loss: 0.4296 - val_accuracy: 0.8431\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8596 - val_loss: 0.4184 - val_accuracy: 0.8517\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3821 - accuracy: 0.8609 - val_loss: 0.4592 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020AE0858F88>,\n",
       "                   iid='deprecated', n_iter=5, n_jobs=None,\n",
       "                   param_distributions={'n_hidden': [3, 5, 7],\n",
       "                                        'n_neurons': [10, 25, 50]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def build_model(n_hidden=10, n_neurons=30,learning_rate=3e-1, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential() \n",
    "    model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))  #if we used inputLayer here instead Flatten, than we may have problem . Why? in the book .d\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# mse_test = keras_reg.score(X_test, y_test)\n",
    "# y_pred = keras_reg.predict(X_new)\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [3, 5, 7],\n",
    "    \"n_neurons\": [10, 25, 50]\n",
    "}\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(X_train, y_train, epochs=40,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=5, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=40,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 50, 'n_hidden': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4220743179321289"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE ###\n",
    "def model_():\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),        \n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")#  If we were doing binary classification or multilabel binary classification, then we would use the \"sigmoid\"\n",
    "                                                    #  (i.e., logistic) activation function in the output layer instead of the \"softmax\"\n",
    "                                                    #  activation function, and we would use the \"binary_crossentropy\" loss.      \n",
    "    ])\n",
    "model=model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "model.evaluate(X_test, y_test) \n",
    "### DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE DENE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(X_train, y_train, epochs=3,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2534 - accuracy: 0.9063 - val_loss: 0.4131 - val_accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb,\n",
    "                              tf.keras.callbacks.EarlyStopping(patience=3, monitor=\"val_loss\")]\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, our best hyperparameters is: ___{'n_neurons': 50, 'n_hidden': 5}___\n",
    "\n",
    "So let's build last one model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8478 - accuracy: 0.6711 - val_loss: 0.5931 - val_accuracy: 0.7509\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 0.6320 - val_accuracy: 0.7769\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4836 - accuracy: 0.8271 - val_loss: 0.4721 - val_accuracy: 0.8335\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4444 - accuracy: 0.8380 - val_loss: 0.4302 - val_accuracy: 0.8501\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4236 - accuracy: 0.8479 - val_loss: 0.4567 - val_accuracy: 0.8402\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4129 - accuracy: 0.8497 - val_loss: 0.4494 - val_accuracy: 0.8380\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8556 - val_loss: 0.4572 - val_accuracy: 0.8358\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3882 - accuracy: 0.8595 - val_loss: 0.3957 - val_accuracy: 0.8578\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3791 - accuracy: 0.8638 - val_loss: 0.4164 - val_accuracy: 0.8520\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3675 - accuracy: 0.8658 - val_loss: 0.4349 - val_accuracy: 0.8518\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8659 - val_loss: 0.4023 - val_accuracy: 0.8561\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3602 - accuracy: 0.8685 - val_loss: 0.3831 - val_accuracy: 0.8628\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3542 - accuracy: 0.8692 - val_loss: 0.4065 - val_accuracy: 0.8585\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3506 - accuracy: 0.8733 - val_loss: 0.3969 - val_accuracy: 0.8668\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3446 - accuracy: 0.8740 - val_loss: 0.3966 - val_accuracy: 0.8577\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3397 - accuracy: 0.8755 - val_loss: 0.3928 - val_accuracy: 0.8667\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3374 - accuracy: 0.8767 - val_loss: 0.3895 - val_accuracy: 0.8668\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3346 - accuracy: 0.8775 - val_loss: 0.4011 - val_accuracy: 0.8554\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3297 - accuracy: 0.8801 - val_loss: 0.4012 - val_accuracy: 0.8643\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3302 - accuracy: 0.8806 - val_loss: 0.4204 - val_accuracy: 0.8591\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3325 - accuracy: 0.8789 - val_loss: 0.3809 - val_accuracy: 0.8680\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3201 - accuracy: 0.8825 - val_loss: 0.3896 - val_accuracy: 0.8717\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8837 - val_loss: 0.4343 - val_accuracy: 0.8581\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3208 - accuracy: 0.8832 - val_loss: 0.4110 - val_accuracy: 0.8636\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3227 - accuracy: 0.8821 - val_loss: 0.4290 - val_accuracy: 0.8559\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3291 - accuracy: 0.8816 - val_loss: 0.3965 - val_accuracy: 0.8713\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3202 - accuracy: 0.8844 - val_loss: 0.3800 - val_accuracy: 0.8731\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3095 - accuracy: 0.8869 - val_loss: 0.3914 - val_accuracy: 0.8722\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3086 - accuracy: 0.8872 - val_loss: 0.4246 - val_accuracy: 0.8595\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8873 - val_loss: 0.4309 - val_accuracy: 0.8659\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8884 - val_loss: 0.4870 - val_accuracy: 0.8492\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3086 - accuracy: 0.8879 - val_loss: 0.3973 - val_accuracy: 0.8634\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3032 - accuracy: 0.8897 - val_loss: 0.3917 - val_accuracy: 0.8679\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8896 - val_loss: 0.3764 - val_accuracy: 0.8759\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8906 - val_loss: 0.4068 - val_accuracy: 0.8665\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3009 - accuracy: 0.8890 - val_loss: 0.4307 - val_accuracy: 0.8603\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8892 - val_loss: 0.3995 - val_accuracy: 0.8726\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3051 - accuracy: 0.8910 - val_loss: 0.3911 - val_accuracy: 0.8768\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3055 - accuracy: 0.8915 - val_loss: 0.4082 - val_accuracy: 0.8693\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8925 - val_loss: 0.5243 - val_accuracy: 0.8427\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2940 - accuracy: 0.8946 - val_loss: 0.3983 - val_accuracy: 0.8719\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2927 - accuracy: 0.8962 - val_loss: 0.3953 - val_accuracy: 0.8733\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2895 - accuracy: 0.8974 - val_loss: 0.3959 - val_accuracy: 0.8715\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3071 - accuracy: 0.8903 - val_loss: 0.4105 - val_accuracy: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d957d77c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_NEURONS= 50\n",
    "N_HIDDEN= 5\n",
    "\n",
    "model_manuelly=keras.models.Sequential()\n",
    "model_manuelly.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "for layer in range(N_HIDDEN):\n",
    "        model_manuelly.add(keras.layers.Dense(N_NEURONS, activation=\"relu\"))\n",
    "model_manuelly.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        \n",
    "model_manuelly.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "    metrics=[\"accuracy\"]) \n",
    "\n",
    "model_manuelly.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid),\n",
    "    callbacks=[[tensorboard_cb], [keras.callbacks.EarlyStopping(patience=10)]])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3712 - accuracy: 0.8657 - val_loss: 0.4244 - val_accuracy: 0.8474\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3682 - accuracy: 0.8669 - val_loss: 0.4695 - val_accuracy: 0.8406\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3696 - accuracy: 0.8662 - val_loss: 0.4102 - val_accuracy: 0.8572\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8680 - val_loss: 0.4016 - val_accuracy: 0.8614\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3554 - accuracy: 0.8697 - val_loss: 0.4602 - val_accuracy: 0.8399\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8710 - val_loss: 0.4078 - val_accuracy: 0.8557\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3507 - accuracy: 0.8730 - val_loss: 0.4162 - val_accuracy: 0.8591\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3545 - accuracy: 0.8732 - val_loss: 0.3919 - val_accuracy: 0.8633\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3578 - accuracy: 0.8721 - val_loss: 0.4365 - val_accuracy: 0.8497\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3644 - accuracy: 0.8696 - val_loss: 0.4141 - val_accuracy: 0.8597\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3586 - accuracy: 0.8712 - val_loss: 0.4414 - val_accuracy: 0.8462\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3586 - accuracy: 0.8719 - val_loss: 0.4049 - val_accuracy: 0.8589\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3505 - accuracy: 0.8746 - val_loss: 0.3908 - val_accuracy: 0.8644\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3446 - accuracy: 0.8775 - val_loss: 0.4143 - val_accuracy: 0.8466\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3465 - accuracy: 0.8757 - val_loss: 0.4144 - val_accuracy: 0.8577\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3404 - accuracy: 0.8763 - val_loss: 0.4423 - val_accuracy: 0.8512\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3392 - accuracy: 0.8790 - val_loss: 0.3891 - val_accuracy: 0.8685\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3368 - accuracy: 0.8790 - val_loss: 0.4161 - val_accuracy: 0.8647\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3271 - accuracy: 0.8814 - val_loss: 0.4617 - val_accuracy: 0.8587\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3501 - accuracy: 0.8737 - val_loss: 0.4214 - val_accuracy: 0.8608\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3317 - accuracy: 0.8802 - val_loss: 0.4987 - val_accuracy: 0.8014\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3301 - accuracy: 0.8810 - val_loss: 0.4294 - val_accuracy: 0.8521\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3326 - accuracy: 0.8795 - val_loss: 0.4460 - val_accuracy: 0.8552\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3366 - accuracy: 0.8791 - val_loss: 0.4568 - val_accuracy: 0.8487\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8832 - val_loss: 0.4203 - val_accuracy: 0.8575\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3284 - accuracy: 0.8807 - val_loss: 0.4232 - val_accuracy: 0.8614\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3183 - accuracy: 0.8848 - val_loss: 0.4017 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20afd27ed48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid),\n",
    "             callbacks=[[tensorboard_cb], \n",
    "                        [keras.callbacks.EarlyStopping(patience=10)],\n",
    "                       [keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41390350461006165, 0.8567000031471252]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lest's apply ***Hyperas***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperas in c:\\users\\bedir\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (0.2.5)\n",
      "Requirement already satisfied: nbformat in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (5.0.4)\n",
      "Requirement already satisfied: keras in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (2.4.3)\n",
      "Requirement already satisfied: jupyter in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (5.6.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperas) (0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.4.1)\n",
      "Requirement already satisfied: future in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.19.5)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (2.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from hyperopt->hyperas) (4.42.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (4.6.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbformat->hyperas) (4.3.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from keras->hyperas) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from keras->hyperas) (5.3)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (7.5.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (5.1.4)\n",
      "Requirement already satisfied: notebook in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.0.3)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (4.6.0)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter->hyperas) (6.1.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (2.5.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.6.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (2.11.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from nbconvert->hyperas) (0.4.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt->hyperas) (4.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (1.7.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (0.15.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->hyperas) (227)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from h5py->keras->hyperas) (1.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (7.12.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->hyperas) (5.3.4)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.7.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (18.1.1)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from notebook->jupyter->hyperas) (0.8.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->hyperas) (3.0.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->hyperas) (2.2.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.4.3)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.14.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.8)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\bedir\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
